---
title: "BlurbDelver Documentation"
author: "Jesse Brown"
date: "2024-11-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(repos = c(CRAN = "https://cloud.r-project.org/"))
install.packages("tidyverse")
install.packages("stringr")
install.packages("tidytext")
install.packages("sentimentr")
install.packages("wordcloud")
install.packages("tm")
install.packages("igraph")
install.packages("textdata")
install.packages("textclean")
install.packages("ggplot2")

library(tidyverse)
library(stringr)
library(tidytext)
library(sentimentr)
library(wordcloud)
library(tm)
library(igraph)
library(textdata)
library(textclean)
library(ggplot2)
```

### Explanation of Layout:
1. **Title & Metadata**: At the top of the document, we have the title, author, date, and output format.
2. **Setup Chunk**: The `setup` chunk hides any initial setup code (like loading libraries or setting options) for cleaner output.
3. **Overview**: A brief description of what the package does and what features it will have.
4. **Function Placeholders**: Each planned function has a description, skeleton code, and an example. These sections serve as placeholders for the full implementation that will be added later.
5. **Future Development**: Outlines future features and improvements.
6. **Key Points & Final Thoughts**: Summarizes the structure of the documentation and reflects on how it serves as both a guide and a blueprint for future development.

## Overview

**BlurbDelver** is an R package designed to help user wrangle and analyze text data like tweets, posts, or comments in a simple and easy manor. Its primary features include:
1. **Tokenization**: Breaking down text into individual words.
2. **Sentiment Analysis**: Determining the tone of the text (positive, negative, neutral).
3. **Word Clouds**: Visualizing word frequencies or sentiment distributions.

---


## Example Functions
These are gutted example of the functions to come:

### **1. TokenizeText**
This function splits a block of text into individual tokens (words)
```{r, echo=FALSE}
TokenizeText <- function(text) {
  unlist(strsplit(text, "\\s+"))
}
# Example
TokenizeText("This is an example tweet!")
# Expected Output: c("This", "is", "an", "example", "tweet!")
```

### **2. SentimentAnalysis**
This code creates a sentiment analysis on the inputted text.

```{r, echo=FALSE}
SentimentAnalysis <- function(text) {
  # Actual implementation to follow
  list(positive = 5, negative = 2, neutral = 3)
}
# Example
SentimentAnalysis("This is a fantastic day, but it could be better.")
# Expected Output: 
#$positive
#[1] 5
#
#$negative
#[1] 2
#
#$neutral
#[1] 3

```

### **3. CreateWordCloud**
This function will create a word cloud out of the given text input.

```{r, echo=FALSE}
CreateWordCloud <- function(text) {
  # Actual implementation to follow
  cat("Word cloud coming soon..")
}
# Example
CreateWordCloud("This is an example tweet!")
# Expected Output is a generated wordcloud plot using all the words given, and showing a bigger word for the ones that are more commonly used. 
```

### Wrap-ups:

- **Future Development**: We plan to add varaious capabilities such as stopword removal, sentiment visualization, and the ability to customize the wordcloud output

- **Key Points & Final Thoughts**: This is still the early parts of the designing of the package. So far, only the barebone outline of the package has been created, with more coming soon. Next up in devlopment is the filling out of the incorporated functions, as well as the addition of future developments planned. 
